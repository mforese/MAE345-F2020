{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LQR Control of a Quadrotor\n",
    "\n",
    "In this lab, we are going to use a hover state linearization of the quadrotor, like you wrote in the previous lab to allow the quadrotor to hover. First, we are going to import the various classes and functions we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mae345 import plotting, Crazyflie as CF, animate_quad\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.linalg import solve_continuous_are\n",
    "from IPython.display import HTML, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (20 Pts)\n",
    "\n",
    "Now, in the cell below, you will fillout the function that will actually solve the LQR problem. That is, given the matrices $\\mathbf{A}, \\mathbf{B}, \\mathbf{Q}, \\mathbf{R}$, you should compute the $K$ that minimizes the LQR cost function. You are encouraged to use the function `scipy.linalg.solve_continuous_are` to solve the CARE. Also, we use the convention that the stabilizing control input is given by $\\mathbf{u} = \\mathbf{K}\\mathbf{x}$ (as opposed to $\\mathbf{u} = -\\mathbf{K}\\mathbf{x}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lqr(A: np.ndarray, B: np.ndarray, Q: np.ndarray, R: np.ndarray) -> np.ndarray:\n",
    "    P = \n",
    "    K = \n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (20 Pts)\n",
    "\n",
    "Next, you will use all the code you have written thus far to actually stabilize your quadrotor in simulation. The following code implements a version of the Crazyflie (a quadrotor) class from our `mae345` library that uses the linearization and LQR functions you just wrote. This class is useful as it provides simulation and animation functionality to verify your controller is working. \n",
    "\n",
    "If we were working with the physical Crazyflie, we would load $\\mathbf{K}$ for control. Additional tuning of the gains after tuning in simulation may be necessary when porting to hardware.\n",
    "\n",
    "\n",
    "### LQR Design \n",
    "\n",
    "Here you will design the LQR controller and then simulate it.\n",
    "\n",
    "The following cell uses the `lqr` function you just wrote in conjunction with our implementation of the linearization function from the previous lab (here as `self.hover_state_linearization()`) to create an instance of the `CrazyflieLQR` class. The details of this process are not important, but this class provides a lot of functionality for designing the LQR controller. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrazyflieLQR(CF):\n",
    "    def __init__(self, Q: np.ndarray, R: np.ndarray, hover_pos: np.ndarray):\n",
    "        super().__init__()\n",
    "        self._hover_pos = hover_pos\n",
    "        self._hover_state = np.concatenate([self._hover_pos, np.zeros(9)])\n",
    "        A, B =  self.hover_state_linearization()\n",
    "        self._K = lqr(A, B, Q, R)\n",
    "        \n",
    "        print('Using K matrix:')\n",
    "        print()\n",
    "        print(self._K)\n",
    "                \n",
    "    @property\n",
    "    def K(self) -> np.ndarray:\n",
    "        return self._K\n",
    "    \n",
    "    def controller(self, state: np.ndarray, t: float) -> np.ndarray:\n",
    "        return self._K @ (state - self._hover_state) + np.array([self.mass * self.gravity, 0, 0, 0])\n",
    "\n",
    "    def set_goal_state(self, hover_state: np.ndarray):\n",
    "        self._hover_state = hover_state        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Part A (10 pts)\n",
    "Provided below are untuned Q and R matrices. Tune these such that system stabilizes to a hover at $x = 0, y = 0, z = 0$ (within $\\pm 0.025$) and with steady state angles $\\phi=\\theta=\\psi=0$ (within $\\pm 0.05$) in 3 seconds or less. (Hint: view the plots of the state variables using the untuned Q and R matrices to determine where improvement can be made. Example: if theta is not stabilizing well, crank up the fifth element on the diag of Q.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# untuned Q and R\n",
    "Q = np.diag([10, 10, 10, 0.0001, 0.0001, 0.0001, 100, 100, 1, 0.005, 0.005, 1])\n",
    "R = 2 * np.diag([1e2, 1e6, 1e6, 1e2])\n",
    "\n",
    "# tuned Q and R\n",
    "Q = \n",
    "R = \n",
    "\n",
    "quad = CrazyflieLQR(Q, R, np.zeros(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell simulates the quadrotor flying with a random initial condition for five seconds and plots some of the states. Use the plots to verify that the system stabilizes and meets the performance objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment the following line if you want to do not want to use the same random initial condition.\n",
    "np.random.seed(42)\n",
    "\n",
    "ic = np.random.rand(12) * 1.2\n",
    "ic[0:3] = ic[0:3] / 5\n",
    "ic[6:9] = ic[6:9] / 5\n",
    "\n",
    "times, states, inputs = quad.simulate(ic, 5, 0.01, clip_input=False)\n",
    "\n",
    "#%matplotlib notebook\n",
    "plt.rcParams[\"figure.figsize\"] = (16,8)\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(121, title='Position')\n",
    "ax.plot(times, states[0, :], label='x')\n",
    "ax.plot(times, states[1, :], label='y')\n",
    "ax.plot(times, states[2, :], label='z')\n",
    "ax.axvline(x=3, linestyle='--', color='k', linewidth=0.8, label='time constraint')\n",
    "ax.axhline(y=0.025, linestyle='--', color='r', linewidth=0.8, label='error bound')\n",
    "ax.axhline(y=-0.025, linestyle='--', color='r', linewidth=0.8)\n",
    "ax.legend()\n",
    "\n",
    "ax = fig.add_subplot(122, title='Angles')\n",
    "ax.plot(times, states[3, :], label='phi')\n",
    "ax.plot(times, states[4, :], label='theta')\n",
    "ax.plot(times, states[5, :], label='psi')\n",
    "ax.axvline(x=3, linestyle='--', color='k', linewidth=0.8, label='time constraint')\n",
    "ax.axhline(y=0.05, linestyle='--', color='r', linewidth=0.8, label='error bound')\n",
    "ax.axhline(y=-0.05, linestyle='--', color='r', linewidth=0.8)\n",
    "ax.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell optionally animates the simulation data computed and plotted in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_quad(0.1, states).save('./anim.gif', writer='pillow', fps=100)\n",
    "Image(url='./anim.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the process you used to tune your gains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Part B (10 pts)\n",
    "Often times, it is important to keep your control effort minimal (e.g., to keep power consumption minimal). Now, tune Q and R to meet the same performance objectives in Part A within 4 seconds and with the control input never exceeding 0.32. Note that $m*g = 0.29$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned Q and R\n",
    "Q = \n",
    "R = \n",
    "\n",
    "quad = CrazyflieLQR(Q, R, np.zeros(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment the following line if you want to do not want to use the same random initial condition.\n",
    "np.random.seed(42)\n",
    "\n",
    "ic = np.random.rand(12) * 1.2\n",
    "ic[0:3] = ic[0:3] / 5\n",
    "ic[6:9] = ic[6:9] / 5\n",
    "\n",
    "times, states, inputs = quad.simulate(ic, 5, 0.01, clip_input=False)\n",
    "\n",
    "#%matplotlib notebook\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 20)\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(311, title='Position')\n",
    "ax.plot(times, states[0, :], label='x')\n",
    "ax.plot(times, states[1, :], label='y')\n",
    "ax.plot(times, states[2, :], label='z')\n",
    "ax.axvline(x=4, linestyle='--', color='k', linewidth=0.8, label='time constraint')\n",
    "ax.axhline(y=0.025, linestyle='--', color='r', linewidth=0.8, label='error margin')\n",
    "ax.axhline(y=-0.025, linestyle='--', color='r', linewidth=0.8)\n",
    "ax.legend()\n",
    "\n",
    "ax = fig.add_subplot(312, title='Angles')\n",
    "ax.plot(times, states[3, :], label='phi')\n",
    "ax.plot(times, states[4, :], label='theta')\n",
    "ax.plot(times, states[5, :], label='psi')\n",
    "ax.axvline(x=4, linestyle='--', color='k', linewidth=0.8, label='time constraint')\n",
    "ax.axhline(y=0.05, linestyle='--', color='r', linewidth=0.8, label='error margin')\n",
    "ax.axhline(y=-0.05, linestyle='--', color='r', linewidth=0.8)\n",
    "ax.legend()\n",
    "\n",
    "ax = fig.add_subplot(313, title='Control Input')\n",
    "ax.plot(times, inputs[0, :], label='u1')\n",
    "ax.plot(times, inputs[1, :], label='u2')\n",
    "ax.plot(times, inputs[2, :], label='u3')\n",
    "ax.plot(times, inputs[3, :], label='u4')\n",
    "ax.axhline(y=0.32, linestyle='--', color='r', linewidth=0.8, label='input bound')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_quad(0.1, states).save('./anim.gif', writer='pillow', fps=100)\n",
    "Image(url='./anim.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the process you used to tune your gains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (25 pts)\n",
    "\n",
    "Next, we will use our tuned LQR controller (from either problem 2a or 2b) to not just hover, but follow a trajectory. In this problem, we will try to follow the path of a 3-D parametric curve given by the following equations:\n",
    "\n",
    "$$\\begin{align} x(t) = t, y(t) = sin(2t), z(t) = cos(2t)  \\end{align}$$\n",
    "\n",
    "This corresponds to circling in the y and z plane, while moving at a constant speed in the x direction: spiraling in the +x direction. In order to follow this path, we will need to make it into a series of waypoints, and then use LQR to follow them consecutively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Part A (10 pts)\n",
    "\n",
    "Create a series of 30 waypoints for the **state** of the quadrotor. Note that the state vector includes 12 states, and we may want to specify more than just the position at a given time. The time should range from $t = 0$ to $t = 3*\\pi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_waypoints = \n",
    "total_time = \n",
    "\n",
    "times = \n",
    "waypoints = \n",
    "\n",
    "for i in range(num_waypoints):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Part B (15 pts)\n",
    "\n",
    "#### B.i (5 pts)\n",
    "First we must write the code that will follow the way points. We begin by hovering for 1 second to stabilize from the randomized initial condition. Then, we can accomplish movement by telling our LQR controller to, instead of hovering, go to the next waypoint for the amount of time in a timestep. We carry on through the waypoints sequentially until we run out of waypoints. Note that `CrazyflieLQR` class function `set_goal_state` will change the LQR's goal state. \n",
    "\n",
    "In order to complete your simulation, you will need to use quad.simulate(). This function takes the following inputs:\n",
    "\n",
    "    ic: A 12-dimensional vector specifying the initial condition of the system.\n",
    "    duration: The duration of the simulated trajectory.\n",
    "    timestep: The timestep to use for the simulation. If None, solve_ivp determines the steps.\n",
    "    clip_input: If True, the input is clipped using ``clipped_controller``. Otherwise unclipped\n",
    "                           signal is used.\n",
    "                  \n",
    "                  \n",
    "And returns the following outputs: \n",
    "\n",
    "    A tuple (t, x, u), where t is a vector containing the times at which the trajectory was evaluated,\n",
    "    x is a matrix containing the corresponding states as columns\n",
    "    and u is a matrix containing the corresponding inputs as columns.\n",
    "\n",
    "#### B.ii (10 pts)\n",
    "Then, tune the Q and R matricies such that the total distance to the goal position on the parametric trajectory doesn't exceed $0.5$ at any point in time. The matplotlib below will show you useful information once you've completed part B.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned Q and R\n",
    "Q = \n",
    "R = \n",
    "quad = CrazyflieLQR(Q, R, np.zeros(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment the following line if you want to do not want to use the same random initial condition.\n",
    "np.random.seed(42)\n",
    "\n",
    "ic = np.random.rand(12)\n",
    "ic[0:3] = ic[0:3] / 20 + np.array([0,0,1])\n",
    "ic[3:] = ic[3:] / 10\n",
    "\n",
    "# set_goal_state takes the desired state vector at each time as input\n",
    "quad.set_goal_state(np.concatenate([np.array([0,0,1]), np.zeros(9)]))\n",
    "times, states, inputs = quad.simulate(ic, 1, 0.01, clip_input=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_waypoints):\n",
    "    # Fill in code to follow waypoints here\n",
    "    quad.set_goal_state(       )\n",
    "    times_temp, states_temp, inputs_temp = quad.simulate(       , clip_input=False)\n",
    "    \n",
    "    \n",
    "    times = np.append(times, times_temp + times[-1]) \n",
    "    states = np.append(states, states_temp, axis=1)\n",
    "    inputs = np.append(inputs, inputs_temp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "plt.rcParams[\"figure.figsize\"] = (16,8)\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(121, title='Trajectory', projection='3d')\n",
    "#ax = ax.axes(projection='3d')\n",
    "xline = np.linspace(0, 3*np.pi, 1000)\n",
    "yline = np.sin(2*xline)\n",
    "zline = np.cos(2*xline)\n",
    "ax.plot(xline, yline, zline, '--k',label = 'Target Trajectory')\n",
    "ax.plot(states[0,:], states[1,:], states[2,:], label = 'Simulated Trajectory')\n",
    "ax.legend()\n",
    "\n",
    "ax = fig.add_subplot(122, title='Position Error')\n",
    "x_state = np.copy(states[0, :])\n",
    "x_state[100:] -= times[100:]-1\n",
    "y_state = np.copy(states[1, :])\n",
    "y_state[100:] -= np.sin(2*(times[100:]-1))\n",
    "z_state = np.copy(states[2, :])\n",
    "z_state[:100] -= 1\n",
    "z_state[100:] -= np.cos(2*(times[100:]-1))\n",
    "ax.plot(times, x_state, label='x error')\n",
    "ax.plot(times, y_state, label='y error')\n",
    "ax.plot(times, z_state, label='z error')\n",
    "ax.plot(times, np.sqrt(x_state**2 + y_state**2 + z_state**2), label='distance from goal') \n",
    "ax.axhline(y=0.5, linestyle='--', color='r', linewidth=0.8, label='error margin')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_quad(0.1, states).save('./anim.gif', writer='pillow', fps=100)\n",
    "Image(url='./anim.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the process you used to tune your gains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
